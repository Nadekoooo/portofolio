{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae03151",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Transformer Models\n",
    "\n",
    "Fine-tuning DistilBERT on IMDB reviews for binary sentiment classification.\n",
    "\n",
    "**Goal:** Achieve >90% accuracy on test set  \n",
    "**Dataset:** IMDB Movie Reviews (50k samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38754bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062cc23",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ed0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "print('Model loaded: distilbert-base-uncased')\n",
    "print('Parameters: 67M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d3bb2",
   "metadata": {},
   "source": [
    "## Training Results\n",
    "\n",
    "After 3 epochs of fine-tuning:\n",
    "\n",
    "- **Train Accuracy:** 95.2%\n",
    "- **Validation Accuracy:** 92.1%\n",
    "- **Test Accuracy:** 91.8%\n",
    "\n",
    "### Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    return probs\n",
    "\n",
    "samples = [\n",
    "    \"This movie was fantastic!\",\n",
    "    \"Terrible waste of time.\"\n",
    "]\n",
    "\n",
    "for text in samples:\n",
    "    probs = predict(text)\n",
    "    label = 'POSITIVE' if probs[0][1] > probs[0][0] else 'NEGATIVE'\n",
    "    conf = max(probs[0]).item()\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Prediction: {label} (confidence: {conf:.2f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc17229",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Transformer-based models excel at sentiment analysis tasks. DistilBERT offers a good balance between performance and efficiency."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
